---
title: "bellabeat_analysis"
author: "Nicole Pierre"
date: "10/13/2025"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Business Task

Analyze data collected from a competitor's products to uncover trends, insights, and recommendations to present to stakeholders. 

## Questions Our Analysis Should Answer

- What are some trends in smart device usage?
- How could these trends apply to Bellabeat customers?
- How could these trends help influence Bellabeat marketing strategies?

## Loading Necessary Packages
```{r load packages}
library(tidyverse)
library(lubridate)
library(dplyr)
```

## The Data

The data used for this analysis was collected from fitbit users and can be found [here](https://www.kaggle.com/datasets/arashnic/fitbit/data).

## Cleaning the Datasets

First, lets load the datasets into R.


```{r load data sets}
activity <- read.csv("/Users/nicolebroussard/Documents/Google_DA_Cert /Case Study/Bellabeat-Fitbit-Analysis-R/Data/dailyActivity_merged.csv")
calories <- read.csv("/Users/nicolebroussard/Documents/Google_DA_Cert /Case Study/Bellabeat-Fitbit-Analysis-R/Data/hourlyCalories_merged.csv")
heartrate <- read.csv("/Users/nicolebroussard/Documents/Google_DA_Cert /Case Study/Bellabeat-Fitbit-Analysis-R/Data/heartrate_seconds_merged.csv")
intensities <- read_csv("/Users/nicolebroussard/Documents/Google_DA_Cert /Case Study/Bellabeat-Fitbit-Analysis-R/Data/hourlyIntensities_merged.csv")
steps <- read_csv("/Users/nicolebroussard/Documents/Google_DA_Cert /Case Study/Bellabeat-Fitbit-Analysis-R/Data/hourlySteps_merged.csv")
```


# Fix Data Types

After viewing the data sets, the date column data types are incorrect. The date columns should be a datetime string. While changing the data type I will be splitting the date and time into two different columns for analysis.


```{r fix data types}
#activity
activity$ActivityDate <- as.POSIXct(activity$ActivityDate, format = "%m/%d/%Y", tz = "GMT")
activity$Date <- format(activity$ActivityDate, "%m/%d/%y")
#calories
calories$ActivityHour <- as.POSIXct(calories$ActivityHour, format = "%m/%d/%Y %I:%M:%S %p", tz = "GMT")
calories$Date <- format(calories$ActivityHour, format = "%m/%d/%y")
calories$Time <- format(calories$ActivityHour, format = "%H:%M:%S")
#heartrate
heartrate$Time <- as.POSIXct(heartrate$Time, format = "%m/%d/%Y %I:%M:%S %p", tz = "GMT")
heartrate$Date <- format(heartrate$Time, "%m/%d/%y")
heartrate$Time2 <- format(heartrate$Time, "%H:%M:%S")
#intensities
intensities$ActivityHour <- as.POSIXct(intensities$ActivityHour, format= "%m/%d/%Y %I:%M:%S %p", tz = "GMT")
intensities$Date <- format(intensities$ActivityHour, "%m/%d/%y")
intensities$Time <- format(intensities$ActivityHour, "%H:%M:%S")
#steps
steps$ActivityHour <- as.POSIXct(steps$ActivityHour, format = "%m/%d/%Y %I:%M:%S %p", tz = "GMT")
```


```{r fix data types2}
steps$Date <- format(steps$ActivityHour, "%m/%d/%y")
steps$Time <- format(steps$ActivityHour, "%H:%M:%S")
```

# Search for NA Values


Now let's search for NA values that could cause issues during our analysis. 


```{r NA}
colSums(is.na(activity))
colSums(is.na(calories))
colSums(is.na(heartrate))
sum(is.na(intensities))
sum(is.na(steps))
```

# Summarize the Data


Now that the data is clean, I will use the summarize function to gather some insights into the columns in each data set.   


```{r sum activity}
summary(activity)
```


Looking at these insights, the average steps tracked by these users per day is 6,547. As well as the average calories burned are 2,189. The LightActiveDistance has the highest average over VeryActive, ModeratelyActive, and SedentaryActive. This makes sense because normally people only hit moderate or very active when they are in a workout. Most of the time people are commuting to and from places which would fall under LightActive. 


```{r sum calories}
summary(calories)
```


The average calories burned in an hour is 94.


```{r sum heartrate}
summary(heartrate)
```


Your heart rate during exercise should fall within the 50%-85% range of your maximum heart rate. To put some of these values into perspecive, I calculated my target heart rate zone. As a 27 year old female my estimated target heart rate zone is 96.5 - 164.05. When I get past the middle of this range (~135), I get into the moderate intensitiy zone. The average heart rate from this data is 79.76. The avergae isn't much use since it is avergaing all heartrates throughout the day (resting and active). This number would need more context like age data or what someone's heart rate is during certain levels of intensity to truly understand its meaning.


```{r sum steps}
summary(steps)
```


The average steps in an hour is 286.

# Number of Unique Participants

This will show us how many people's data are in each data set we will use for analysis. 


```{r}
n_distinct(activity$Id)
n_distinct(steps$Id)
n_distinct(calories$Id)
```


Normally, we would like a larger number of participants to make sure our data isn't biased to a specific group of people.

# Merge the Data

Merging the data sets allows me to only analyze the data needed to answer our business questions. 


```{r merge cal and steps}
merged_df <- inner_join(calories, steps, by = c("Id", "ActivityHour", "Date", "Time"))
#head(merged_df)
```

```{r find mean cal}
df_avg_by_hour <- merged_df %>%
  group_by(Time) %>%
  summarise(avg_value = mean(Calories, na.rm = TRUE))
```


```{r avg cal desc}
df_avg_by_hour_sorted <- arrange(df_avg_by_hour, desc(avg_value))
```

# Analyze the Data

We will start by analyzing calorie and step data separately and then together.  


```{r line plot}
calories_over_time <- ggplot(data = df_avg_by_hour, aes(x=Time, y=avg_value)) +
  geom_line(aes(group=1)) +
  geom_point() +
  ggtitle( "Average Calories Burned Throughout the Day") +
  labs(x = "Time of Day",
       y = "Average Calories") +
  theme(axis.text.x = element_text(angle = 90)) +
  geom_text(aes(label = ifelse(avg_value == max(avg_value), as.character(round(avg_value), digits = 2), "")), color = "blue", vjust = -.25)
calories_over_time
```


By looking at the line graph you can see that the time of day with the highest average calories burned is at 19:00 or 7:00 PM. The hour between 6:00 PM and 7:00PM seems to be the hour the participants burn the most calories. 


```{r find avg steps}
df_avgStep_by_hour <- merged_df %>%
  group_by(Time) %>%
  summarise(avg_value = mean(StepTotal, na.rm = TRUE))
```


```{r steps line graph}
steps_over_time <- ggplot(data = df_avgStep_by_hour, aes(x=Time, y=avg_value)) +
  geom_line(aes(group=1)) +
  geom_point() +
  ggtitle( "Average Step Count Per Hour") +
  labs(x = "Time of Day",
       y = "Average Steps") +
  theme(axis.text.x = element_text(angle = 90)) +
  geom_text(aes(label = ifelse(avg_value == max(avg_value), as.character(round(avg_value), digits = 2), "")), color = "blue", vjust = -.25)
steps_over_time
```


Looking at the line graph, the hour with the highest average step count is also 19:00 or 7:00 PM.


```{r scatterplot}
cal_step_plot <- ggplot(merged_df, aes(x = StepTotal, y = Calories)) +
  geom_point() +
  geom_smooth(method = "lm", se = TRUE, color = "blue") +
  ggtitle("Calories vs Step Total") 
cal_step_plot
```


If it wasn't clear already this scatterplot shows a correlation between calories burned and step count per day. When the step total increases the calories burned increases. 


```{r Avg Calorie per ID}
avg_dailyCalories_df <- activity %>%
  group_by(Id) %>%
  summarise(avg_value = mean(Calories, na.rm = TRUE))

avg_dailyCalories_df2 <- avg_dailyCalories_df %>%
  mutate(bar_color = ifelse(avg_value >= 2000, "red", "green"))
```

```{r Graph Avg Cal per Id}
calories_per_id <- ggplot(avg_dailyCalories_df2, 
                          aes(x = as.character(Id), y = avg_value, fill = bar_color)) +
  geom_col(width = 0.5) +
  theme(axis.text.x = element_text(angle = 90)) +
  geom_hline(yintercept = 2000) +
  ggtitle( "Average Calories Burned per Day per Id") +
    labs(x = "User Id", y = "Calories") 
  #geom_text(aes(label = round(avg_value)), vjust = 0)
calories_per_id
```

In the above bar graph, you can see that the bars that reach 2000 calories burned are colored green and the ones that fall short are red. Studies show that you need to be in a 500 calorie deficit to lose a pound a week. This means you need to burn 500 more calories than you consume per day. If the average women consumes 1500 calories per day then they would need to burn atleast 2000 calories to be on track to lose a pound in a week. After analyzing the data we have some fitbit users meeting that goal and some that are not. 

Disclaimer: Every women is different. The exact number depends on a women's age, actvity level, and weight.

# Reccomendations

- The Bellabeat marketing team could update the Bellabeat app to ask their members questions to allow their app to track if the user is meeting their daily caloric deficit. - The Bellabeat marketing team could enable daily push notifications on the app for when the members are close to their caloric deficit. They could also use a similar graph to show each day of the week and if they met their goal or not.
- The Bellabeat marketing team could use this information to suggest going on a walk when the day is winding down and their member hasn't met their caloric deficit goal. Or maybe a member prioritizes hitting a certain number of burned calories. The member could set their daily burned calories goal and the app could track the progress. 
- In our analysis, we discovered that the most active time of day is 7:00PM. We could assume that we have people that rather work out after work or are running kids around to practices, cooking dinner, and/or playing with their kids. We can market to working mom's and ways they can stay active with common household duties. Quick workouts they can do while waiting for their children to get done with their after school activities. 

